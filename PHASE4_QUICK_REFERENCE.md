# ğŸš€ PHASE 4 QUICK REFERENCE CARD

**Print This. Keep at Desk.** ğŸ“‹

---

## âš¡ WEEK 1 DAILY CHECKLIST

### Monday: Security Audit Day

```
â˜ 9:00 AM   Run kube-bench: ./phase4_execute.sh audit
â˜ 10:00 AM  Scan container images with Trivy
â˜ 11:00 AM  Audit RBAC configuration
â˜ 12:00 PM  Review findings, fix CRITICAL items
â˜ 2:00 PM   Generate security audit report
â˜ 3:00 PM   Team review & sign-off
â˜ 4:00 PM   Document all findings
```

### Tuesday-Wednesday: Staging Deployment

```
â˜ 9:00 AM   Deploy staging: ./phase4_execute.sh staging
â˜ 10:00 AM  Replicate production data to staging
â˜ 11:00 AM  Run load tests: ./phase4_execute.sh load-test
â˜ 12:00 PM  Review test results
â˜ 1:00 PM   START 72-hour soak test: ./phase4_execute.sh soak-test
â˜ 2:00 PM   Monitor soak test metrics
â˜ Daily     Check soak test dashboard (auto-monitoring)
```

### Thursday: Production Prep

```
â˜ 9:00 AM   Set up blue-green: ./phase4_execute.sh blue-green
â˜ 10:00 AM  Smoke test green environment
â˜ 11:00 AM  Configure traffic mirroring
â˜ 12:00 PM  Set up rollback automation
â˜ 1:00 PM   Create deployment runbook (if needed)
â˜ 2:00 PM   Brief incident response team
â˜ 3:00 PM   Final sign-off meeting
```

### Friday: Final Verification

```
â˜ 9:00 AM   Security audit final review
â˜ 10:00 AM  Staging validation complete?
â˜ 11:00 AM  Blue-green setup verified?
â˜ 12:00 PM  Rollback automation tested?
â˜ 1:00 PM   Team briefing 2.0 (final checks)
â˜ 2:00 PM   Deployment window scheduled (Tuesday 2 AM)
â˜ 3:00 PM   Week 1 sign-off complete
```

---

## ğŸš€ WEEK 2: DEPLOYMENT DAY (Tuesday 2-6 AM UTC)

### Timeline

```
2:00 AM  â”œâ”€ Deploy script: ./phase4_execute.sh deploy
2:30 AM  â”œâ”€ Green receives 100% shadow traffic
3:00 AM  â”œâ”€ Canary 5% (5% real users on green)
3:30 AM  â”œâ”€ Canary 25%
4:00 AM  â”œâ”€ Canary 50%
4:30 AM  â”œâ”€ Canary 100% (all users on green)
5:00 AM  â”œâ”€ Verify: No issues, all metrics good
5:30 AM  â”œâ”€ Decommission blue
6:00 AM  â””â”€ DEPLOYMENT COMPLETE âœ…
```

### Monitoring During Deployment

```
Open 3 terminals:

Terminal 1: kubectl logs -n production-green deployment/phantommesh -f
Terminal 2: kubectl logs -n production deployment/phantommesh -f
Terminal 3: Watch Grafana: http://grafana:3000/d/production
```

---

## ğŸ“Š SUCCESS METRICS

### Week 1 Audit

```
Security Audit:
âœ… 0 CRITICAL findings (required)
âœ… < 5 HIGH vulnerabilities (acceptable)
âœ… All findings documented
```

### Week 1 Staging

```
Load Test:
âœ… P99 < 100ms (target: 200ms)
âœ… Error rate < 0.1% (target: <1%)
âœ… Peak throughput: 1,050 req/sec

72-Hour Soak:
âœ… Memory usage stable (< 5% growth)
âœ… No pod restarts
âœ… Error rate consistent < 0.1%
```

### Week 2 Deployment

```
Canary Deployment:
âœ… 0 errors during 5% stage
âœ… 0 errors during 25% stage
âœ… 0 errors during 50% stage
âœ… 0 errors during 100% stage
âœ… Total deployment errors: < 5% of traffic

Post-Deployment (24 hours):
âœ… Error rate: < 0.1%
âœ… P99 latency: < 100ms
âœ… Zero unexpected pod restarts
âœ… User reports: 0
```

---

## ğŸ”§ COMMAND QUICK REFERENCE

### Security Audit

```bash
./phase4_execute.sh audit                    # Full security audit
cat audit-reports/audit_*/AUDIT_SUMMARY.md   # Review results
```

### Staging

```bash
./phase4_execute.sh staging                  # Deploy to staging
./phase4_execute.sh load-test                # Run load test
./phase4_execute.sh soak-test                # Start 72-hour test
```

### Blue-Green

```bash
./phase4_execute.sh blue-green               # Set up blue-green
./phase4_execute.sh deploy                   # Execute canary deployment
./phase4_execute.sh health                   # Health check
```

### Manual Kubectl (if needed)

```bash
# Check pod status
kubectl get pods -n production

# View logs
kubectl logs -n production deployment/phantommesh -f

# Check metrics
kubectl top pods -n production

# Manual rollback (if automation fails)
kubectl patch virtualservice phantommesh-canary -n production \
  -p '{"spec":{"http":[{"route":[{"destination":{"host":"phantommesh-blue"},"weight":100}]}]}}'
```

---

## ğŸš¨ EMERGENCY PROCEDURES

### If Something Goes Wrong

#### High Error Rate (> 0.5% for 5 minutes)

```
1. Check: kubectl logs -n production-green deployment/phantommesh | tail -50
2. Decision: Fix or rollback?
   - FIX: kubectl rollout restart deployment/phantommesh -n production-green
   - ROLLBACK: ./phase4_execute.sh rollback (auto-trigger should handle)
3. Notify: Post in #phantommesh-incident
4. Investigate: Don't redeploy until root cause found
```

#### High Latency (P99 > 150ms)

```
1. Check: kubectl top pods -n production-green
2. If high memory: Likely memory leak
3. If high CPU: Likely algorithm issue
4. Rollback to blue: ./phase4_execute.sh rollback
5. Investigate in staging before redeploying
```

#### Pod Crashes (Restart loops)

```
1. Check: kubectl describe pod -n production-green [POD_NAME]
2. View logs: kubectl logs -n production-green [POD_NAME]
3. If OOMKilled: Memory limit too low
4. If CrashLoopBackOff: Code issue
5. Rollback: ./phase4_execute.sh rollback
6. Fix in staging, redeploy in Phase 4 Week 2
```

#### Database Connection Failure

```
1. Check: kubectl exec -n production-green [POD] -- psql -h [HOST] -U postgres -c "SELECT 1;"
2. Verify: Database is accessible and has correct credentials
3. If failed: Database might be down or network issue
4. Rollback: Blue environment uses known-good database
5. Investigate: Check DB health and credentials
```

---

## ğŸ“ ESCALATION PATH

### P1 (Critical) - Page immediately

- Error rate > 1%
- P99 latency > 500ms
- Pod crashes (CrashLoopBackOff)
- Database connectivity lost
- **Action:** Rollback to blue, page on-call engineer

### P2 (High) - Within 15 minutes

- Error rate > 0.5% (but < 1%)
- P99 latency > 150ms
- Memory/CPU trending high
- **Action:** Investigate, decide fix vs rollback

### P3 (Info) - Log for post-mortem

- Error rate 0.1-0.5%
- P99 latency 100-150ms
- Minor metric anomalies
- **Action:** Monitor, document findings

---

## ğŸ“‹ SIGN-OFF CHECKLIST

### Week 1 Sign-Off (Friday)

```
â˜ Security audit: Signed off by Security Lead
â˜ Staging validation: Signed off by SRE Lead
â˜ Soak test (72h): Confirmed passing
â˜ Blue-green setup: Verified and tested
â˜ Rollback automation: Tested and ready
â˜ Team briefing: All procedures understood
â˜ Deployment window: Scheduled (Tuesday 2 AM UTC)

Final Approval:
- DevOps Lead: ____________________
- SRE Lead: _______________________
- CTO: ___________________________
```

### Week 2 Sign-Off (Post-Deployment)

```
â˜ Traffic successfully routed to green (100%)
â˜ Error rate remained < 0.1% throughout deployment
â˜ P99 latency remained < 100ms
â˜ Zero pod crashes during deployment
â˜ Blue environment decommissioned
â˜ Post-deployment monitoring active (24 hours)
â˜ User impact: Zero incidents reported

Final Approval:
- DevOps Lead: ____________________
- VP Engineering: __________________
```

---

## ğŸ“ˆ MONITORING DASHBOARDS

**During Deployment (Keep Open):**

```
1. Grafana Production: http://grafana:3000/d/production
   - P99 latency
   - Error rate
   - Request throughput
   - CPU/Memory usage

2. Kubectl Monitoring:
   kubectl get pods -n production -w

3. Log Monitoring:
   kubectl logs -n production-green -f

4. Status Page: https://phantommesh.statuspage.io
```

---

## ğŸ“ KEY TAKEAWAYS

1. **Automation First:** Use `./phase4_execute.sh` for all major operations
2. **Safety First:** Always verify blue environment is stable before deploying green
3. **Canary Progression:** Never jump from 0% to 100% - use stages
4. **Monitoring:** Have 3 terminals open during deployment
5. **Communication:** Update #phantommesh-deployment every 15 minutes
6. **Rollback Ready:** If anything feels wrong, rollback immediately (30 sec recovery)

---

## ğŸ“ CONTACTS

**Incident Response:**

- On-Call Engineer: [PHONE/SLACK]
- DevOps Lead: [PHONE/SLACK]
- CTO: [PHONE/SLACK]

**Escalation:**

- P1: All three
- P2: On-Call + DevOps Lead
- P3: DevOps Lead (log for review)

**Communication Channels:**

- Real-time: #phantommesh-deployment (Slack)
- Status: phantommesh.statuspage.io
- Post-incident: #phantommesh-postmortem

---

## âœ… FINAL CHECKLIST

**Before Starting Week 1:**

- [ ] All scripts downloaded: `phantom-mesh-vpn/scripts/phase4_execute.sh`
- [ ] Audit directory created: `mkdir -p audit-reports`
- [ ] Backups directory created: `mkdir -p backups`
- [ ] This card printed and posted: âœ“

**Before Starting Week 2:**

- [ ] Week 1 sign-offs obtained
- [ ] Incident response team confirmed ready
- [ ] All monitoring dashboards open
- [ ] Slack notification channels tested
- [ ] Phone numbers verified for escalation

---

**Status: READY TO EXECUTE PHASE 4** ğŸš€

_Last updated: January 4, 2026_  
_Print and keep at desk during Phase 4_  
_Detailed procedures: See PHASE4_EXECUTION_RUNBOOK.md_
